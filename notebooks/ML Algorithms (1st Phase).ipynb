{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb623092",
   "metadata": {},
   "source": [
    "## 1. Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a7084d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6092530e",
   "metadata": {},
   "source": [
    "## 2. Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ab531c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert Data Here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51627e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into the response, y, and features, X\n",
    "y =\n",
    "X = "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80522502",
   "metadata": {},
   "source": [
    "## 3. Train/Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7843122c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44a43933",
   "metadata": {},
   "source": [
    "# Import Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4078f01f",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1668924",
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = LinearRegression()\n",
    "# Fit the model to the training data (also known as training the model)\n",
    "lm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0ba4383",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the intercept, or y-cut, of our linear model\n",
    "a = float(lm.intercept_)\n",
    "# Extract the intercept, or y-cut, of our linear model\n",
    "a = float(lm.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf487eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Slope:\\t\\t\", b)\n",
    "print(\"Intercept:\\t\", float(a))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b96d7a84",
   "metadata": {},
   "source": [
    "Linear Regression Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b47e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the values that fall along our regression line\n",
    "gen_y = lm.predict(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7472770",
   "metadata": {},
   "source": [
    "## Regularisation Rigde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ac5b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create scaler object\n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f8caa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create scaled version of the predictors (there is no need to scale the response)\n",
    "X_scaled_ridge = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c26df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the scaled predictor values into a dataframe\n",
    "X_standardise = pd.DataFrame(X_scaled_ridge,columns=X.columns)\n",
    "X_standardise.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1fe6877",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into train and test, being sure to use the standardised predictors\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_standardise,\n",
    "                                                    y,\n",
    "                                                    test_size=0.2,\n",
    "                                                    shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe89bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create ridge model\n",
    "ridge = Ridge()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9800f06b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "ridge.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7899d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the model intercept value\n",
    "b0 = float(ridge.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "177cd076",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the model coefficient value\n",
    "coeff = pd.DataFrame(ridge.coef_, X.columns, columns=['Coefficient'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a76439a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Intercept:\", float(b0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e30e800b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check out the coefficients\n",
    "coeff"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d17d82e",
   "metadata": {},
   "source": [
    "## Regularisation Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c33620c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create standardization object\n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0958b513",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save standardized features into new variable\n",
    "X_scaled_lasso = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd0e86f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled_lasso,\n",
    "                                                    y,\n",
    "                                                    test_size=0.20,\n",
    "                                                    random_state=1,\n",
    "                                                    shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b632ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso = Lasso(alpha=0.01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d434f7f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6404280",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract intercept from model\n",
    "intercept = float(lasso.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f6cd00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract coefficient from model\n",
    "coeff = pd.DataFrame(lasso.coef_, X.columns, columns=['Coefficient'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c97b417",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract intercept\n",
    "print(\"Intercept:\", float(intercept))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64fa9d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "coeff\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06e12ae3",
   "metadata": {},
   "source": [
    "## Desicion Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cd085c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate regression tree model\n",
    "regr_tree = DecisionTreeRegressor(max_depth=2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a3472fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "regr_tree.fit(x_train,y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daa4be35",
   "metadata": {},
   "source": [
    "## Random Forrest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45650982",
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardize features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X[:,np.newaxis])\n",
    "\n",
    "# Train test split\n",
    "x_train, x_test, y_train,y_test = train_test_split(X_scaled,y,test_size=0.2,random_state=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "341967ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our forest consists of 100 trees with a max depth of 5 in this example\n",
    "RF = RandomForestRegressor(n_estimators=100, max_depth=5)\n",
    "RF.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "634f97a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14165109",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3e63be22",
   "metadata": {},
   "source": [
    "## Testing each model accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10b5c976",
   "metadata": {},
   "outputs": [],
   "source": [
    "#here we will calculate each model's RSME and find which model perfoms best"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e3ef914",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88653348",
   "metadata": {},
   "outputs": [],
   "source": [
    "# comparison linear model\n",
    "slr = LinearRegression()\n",
    "\n",
    "slr.fit(X_train[['column']], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93388bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary of results\n",
    "results_dict = {'Training MSE':\n",
    "                    {\n",
    "                        \"SLR\": metrics.mean_squared_error(y_train, slr.predict(X_train[['column']])),\n",
    "                        \"MLR\": metrics.mean_squared_error(y_train, lm.predict(X_train))\n",
    "                    },\n",
    "                'Test MSE':\n",
    "                    {\n",
    "                        \"SLR\": metrics.mean_squared_error(y_test, slr.predict(X_test[['column']])),\n",
    "                        \"MLR\": metrics.mean_squared_error(y_test, lm.predict(X_test))\n",
    "                    },\n",
    "                'Test RMSE':\n",
    "                    {\n",
    "                        \"SLR\": math.sqrt(metrics.mean_squared_error(y_test, slr.predict(X_test[['column']]))),\n",
    "                        \"MLR\": math.sqrt(metrics.mean_squared_error(y_test, lm.predict(X_test)))\n",
    "                    }\n",
    "                }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8962ff5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataframe from dictionary\n",
    "results_df = pd.DataFrame(data=results_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d18c45d",
   "metadata": {},
   "source": [
    "## Regularisation Ridge "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d7f9fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check training accuracy\n",
    "train_lm = lm.predict(X_train)\n",
    "train_ridge = ridge.predict(X_train)\n",
    "\n",
    "print('Training MSE')\n",
    "print('Linear:', metrics.mean_squared_error(y_train, train_lm))\n",
    "print('Ridge :', metrics.mean_squared_error(y_train, train_ridge))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfc61c82",
   "metadata": {},
   "source": [
    "## Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6684eeb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get predictions for test data\n",
    "y_pred = regr_tree.predict(x_test)\n",
    "\n",
    "# calculate MSE\n",
    "MSE = mean_squared_error(y_pred,y_test)\n",
    "\n",
    "# Report RMSE\n",
    "print(\"Regression Decision Tree model RMSE is:\",np.sqrt(MSE))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18a74944",
   "metadata": {},
   "source": [
    "## Random Forrest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d3ec8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predictions\n",
    "y_pred = RF.predict(x_test)\n",
    "\n",
    "# Compute RMSE\n",
    "print(\"RMSE:\",np.sqrt(mean_squared_error(y_test,y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7b90166",
   "metadata": {},
   "source": [
    "# Model Tuning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5d947a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this section is where we tune each model to get better accuracy \n",
    "from sklearn.ensemble import VotingRegressor\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceecb9b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the models which we'll include in our ensemble. \n",
    "# We pass a list of tuples, which each have a string identifier for the\n",
    "# model (arbitrary choice), along the actual instantiated sklearn model.  \n",
    "models = [(\"LR\",lm),(\"Ridge\",ridge),(\"Lasso\",lasso),(\"RT\",regr_tree)]\n",
    "\n",
    "# Specify weights for weighted model averaging\n",
    "model_weightings = np.array([0.25,0.25,0.25,0.25])\n",
    "v_reg = VotingRegressor(estimators=models,weights=model_weightings)\n",
    "v_reg.fit(X_train,y_train[:,0])\n",
    "\n",
    "\n",
    "y_pred = v_reg.predict(X_test)\n",
    "print(\"RMSE: \", np.sqrt(mean_squared_error(y_test,y_pred)))\n",
    "\n",
    "s_reg.fit(X_train,y_train[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b733331-6a18-49c1-bc79-edf231529580",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_learner_reg = LinearRegression()\n",
    "\n",
    "s_reg = StackingRegressor(estimators=models, final_estimator=meta_learner_reg)\n",
    "\n",
    "y_pred = s_reg.predict(x_test)\n",
    "print(\"RMSE: \", np.sqrt(mean_squared_error(y_test,y_pred)))\n",
    "\n",
    "#Lets take the average of the two ensembling methods.\n",
    "models = [(\"Voting Regression\",v_reg),(\"Stack\",s_reg)]\n",
    "\n",
    "# Specify weights for weighted model averaging\n",
    "model_weightings = np.array([0.25,0.25,0.25,0.25])\n",
    "v_reg = VotingRegressor(estimators=models,weights=model_weightings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66429a3f-2c53-4de0-ac0a-fe560d7a9161",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Logistic Regression\n",
    "c = 0.25\n",
    "response = []\n",
    "testResponse = []\n",
    "\n",
    "for j in y_train[:,0]:\n",
    "    if j > c:\n",
    "        response.append(1)\n",
    "    else:\n",
    "        response.append(0)\n",
    "        \n",
    "for j in y_test[:,0]:\n",
    "    if j > c:\n",
    "        testResponse.append(1)\n",
    "    else:\n",
    "        testResponse.append(0)\n",
    "\n",
    "        \n",
    "        \n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, response)\n",
    "\n",
    "a = lr.intercept_[0]\n",
    "\n",
    "coeff_df = pd.DataFrame(lr.coef_.T, X_transformed.columns, columns=['Coefficient'])\n",
    "coeff_df\n",
    "\n",
    "pred_lm = lr.predict(X_test)\n",
    "\n",
    "confusion_matrix(testResponse, pred_lm)\n",
    "\n",
    "labels = ['0: Low Uptake Rate', '1: High Uptake Rate']\n",
    "\n",
    "pd.DataFrame(data=confusion_matrix(testResponse, pred_lm), index=labels, columns=labels)\n",
    "\n",
    "            \n",
    "            \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
